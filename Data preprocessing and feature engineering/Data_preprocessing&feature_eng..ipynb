{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c377568-dc3d-40bb-b26c-a630c20adea1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the file.\n"
     ]
    }
   ],
   "source": [
    "# load Data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import timedelta\n",
    "\n",
    "try:\n",
    "    df_raw = pd.read_csv('Main.csv')\n",
    "    print(\"Loaded the file.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error no file found\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "401901f4-a843-4d0b-a191-5aef0bcc7226",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 2880 duplicate videos title\n",
      "Data cleaning done\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning\n",
    "def clean_dataframe(df):\n",
    "    \"\"\"\n",
    "    Function to clean the raw dataset\n",
    "    Handles misssing values, misssind value and remove duplicates data types\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # missing values\n",
    "    df_clean['likeCount'] = df_clean['likeCount'].fillna(0)\n",
    "    df_clean['commentCount'] = df_clean['commentCount'].fillna(0)\n",
    "    df_clean['description'] = df_clean['description'].fillna('')\n",
    "\n",
    "    # convert floats to int\n",
    "    df_clean['likeCount'] = df_clean['likeCount'].astype(int)\n",
    "    df_clean['commentCount'] = df_clean['commentCount'].astype(int)\n",
    "    df_clean['published_at'] = pd.to_datetime(df_clean['published_at'])\n",
    "\n",
    "    # Remove Duplicate\n",
    "    rows_before = len(df_clean)\n",
    "    df_clean.drop_duplicates(subset=['title'], keep='first', inplace= True)\n",
    "    rows_after = len(df_clean)\n",
    "    print(f\"Removed {rows_before - rows_after} duplicate videos title\")\n",
    "\n",
    "    df_clean.reset_index(drop=True, inplace = True)\n",
    "    print(\"Data cleaning done\")\n",
    "    return df_clean\n",
    "\n",
    "df_cleaned = clean_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d86d81fe-15a3-4ed5-8686-e4f6d0dba16a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature engineering complete\n",
      "\n",
      "Preview of the final dataframe:\n",
      "      video_id                                              title  \\\n",
      "0  4wZwXhoxRIA  15 Tech Gadgets I Use Every Day #shorts #justi...   \n",
      "1  5fKkXFresYI                      5 Times Tech has SAVED LIVES!   \n",
      "2  KArch4rjU_0  USB in USB #charger #technology #electronic #f...   \n",
      "3  gsJAlLOFBv0                      TINY Tech That Actually Works   \n",
      "4  uvG-WToQfU4                             Old Or New Technology?   \n",
      "\n",
      "                                         description  \\\n",
      "0                                                      \n",
      "1  #shorts #technology \\n\\nI spend a LOT of time ...   \n",
      "2  Maybe stop plugging things into each other to ...   \n",
      "3                                                      \n",
      "4  Follow me here:\\nInstagram â–º https://www.insta...   \n",
      "\n",
      "                                                tags  \\\n",
      "0                                                 []   \n",
      "1                                 [\"tech\", \"shorts\"]   \n",
      "2                                                 []   \n",
      "3  [\"tiny\", \"tech\", \"gadgets\", \"small\", \"miniature\"]   \n",
      "4                                                 []   \n",
      "\n",
      "               published_at                channel_id   channel_title  \\\n",
      "0 2025-01-04 19:26:39+00:00  UCKaWD4ZM7ixlot6ysBVKP_g    Justice Buys   \n",
      "1 2022-10-15 08:25:08+00:00  UCMiJRAwDNSNzuYeN2uWa0pA  Mrwhosetheboss   \n",
      "2 2024-05-12 17:37:14+00:00  UCJ0-OtVpF0wOKEqT2Z1HEtA     ElectroBOOM   \n",
      "3 2025-05-02 17:37:10+00:00  UCMiJRAwDNSNzuYeN2uWa0pA  Mrwhosetheboss   \n",
      "4 2024-07-17 19:15:02+00:00  UCWBWgCD4oAqT3hUeq40SCUw        Sambucha   \n",
      "\n",
      "   category_id duration definition  viewCount  likeCount  commentCount  \\\n",
      "0           22     PT1M         hd   18158007     608799          2513   \n",
      "1           28     PT1M         hd   41069097    2641826          8343   \n",
      "2           28    PT17S         hd   46372126    2128094          5846   \n",
      "3           28    PT57S         hd    9991720     268959           558   \n",
      "4           24     PT1M         hd    3764110     246115          2513   \n",
      "\n",
      "   title_length  published_year  published_month  published_day_of_week  \\\n",
      "0            58            2025                1                      5   \n",
      "1            29            2022               10                      5   \n",
      "2            50            2024                5                      6   \n",
      "3            29            2025                5                      4   \n",
      "4            22            2024                7                      2   \n",
      "\n",
      "   duration_seconds  like_ratio  comment_ratio  \n",
      "0                60    0.033528       0.000138  \n",
      "1                60    0.064326       0.000203  \n",
      "2                17    0.045892       0.000126  \n",
      "3                57    0.026918       0.000056  \n",
      "4                60    0.065385       0.000668  \n"
     ]
    }
   ],
   "source": [
    "# feature engineering\n",
    "\n",
    "def parse_iso8601_duration(duration_str):\n",
    "    \"\"\"\n",
    "    Parses an ISO 8601 duration string - PT1M5S and return the total sec.\n",
    "    \"\"\"\n",
    "    if not isinstance(duration_str, str) or not duration_str.startswith('PT'):\n",
    "        return 0\n",
    "    duration = re.sub(r'^PT', '', duration_str)\n",
    "    seconds = 0\n",
    "    hours_match = re.search(r'(\\d+)H', duration)\n",
    "    minutes_match = re.search(r'(\\d+)M', duration)\n",
    "    seconds_match = re.search(r'(\\d+)S', duration)\n",
    "    if hours_match:\n",
    "        seconds += int(hours_match.group(1)) * 3600\n",
    "    if minutes_match:\n",
    "        seconds += int(minutes_match.group(1)) * 60\n",
    "    if seconds_match:\n",
    "        seconds += int(seconds_match.group(1))\n",
    "    return seconds\n",
    "\n",
    "def create_features(df):\n",
    "    df_featured = df.copy()\n",
    "\n",
    "    df_featured['title_length'] = df_featured['title'].str.len()\n",
    "\n",
    "    df_featured['published_year'] = df_featured['published_at'].dt.year\n",
    "    df_featured['published_month'] = df_featured['published_at'].dt.month\n",
    "    df_featured['published_day_of_week'] = df_featured['published_at'].dt.dayofweek\n",
    "\n",
    "    df_featured['duration_seconds'] = df_featured['duration'].apply(parse_iso8601_duration)\n",
    "\n",
    "    df_featured['like_ratio'] = df_featured['likeCount'] / (df_featured['viewCount'] + 1e-6)\n",
    "    df_featured['comment_ratio'] = df_featured['commentCount'] / (df_featured['viewCount'] + 1e-6)\n",
    "\n",
    "    print(\"feature engineering complete\")\n",
    "    return df_featured\n",
    "\n",
    "if 'df_cleaned' in locals() and not df_cleaned.empty:\n",
    "    df_final = create_features(df_cleaned)\n",
    "\n",
    "    print(\"\\nPreview of the final dataframe:\")\n",
    "    print(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7a8591c-ce0b-4634-b630-23b6d144bf44",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved as 'youtube_data_clean.csv'\n"
     ]
    }
   ],
   "source": [
    "# save the new file\n",
    "if 'df_final' in locals():\n",
    "    output_filename = \"youtube_data_clean.csv\"\n",
    "\n",
    "    try:\n",
    "        df_final.to_csv(output_filename, index=False)\n",
    "        print(f\"file saved as '{output_filename}'\")\n",
    "\n",
    "    except Execption as e:\n",
    "        print(f\"file not saved. An error occurred: {e}\")\n",
    "else:\n",
    "    print(\"file not saved - not found or empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51753209-cf6d-4c1d-8c87-d9e854818b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
